{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdpierse/Siamese-Network/blob/master/siamese_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM7GD9hZS6K-",
        "colab_type": "code",
        "outputId": "6bc82e86-739b-493b-f7be-e5926e4ee9d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cdpierse/Siamese-Network.git siamese_network\n",
        "%cd siamese_network\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'siamese_network'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 6188 (delta 6), reused 9 (delta 3), pack-reused 6173\u001b[K\n",
            "Receiving objects: 100% (6188/6188), 198.46 MiB | 39.61 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "Checking out files: 100% (5957/5957), done.\n",
            "/content/siamese_network\n",
            "data\t\t __init__.py   model.py\t\t      test.py\n",
            "dockerfile\t loader.py     requirements.txt\n",
            "environment.yml  makepairs.py  siamese_network.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY3SVUY4MLqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSDEN71TdnB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model, Sequential\n",
        "from tensorflow.keras.layers import (Conv2D, Dense, Flatten, Lambda,\n",
        "                                     MaxPooling2D, Dropout, SpatialDropout2D)\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.backend import abs, sum, square, sqrt\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.metrics import accuracy_score\n",
        "from model import fetch_train_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EI_tlB0np4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_distance(left_input,right_input):\n",
        "  return sqrt(sum(square(left_input-right_input),axis=1,keepdims=True))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psm-f2mIWjNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def siamese_model(input_shape):\n",
        "    \"\"\"Defines architecture for siamese network. Should be two identically\n",
        "    weighted conv nets with a distance function layer at the end to differentiate \n",
        "    and produce a similarity score. This is similarity based metric not a classification \n",
        "    task.\n",
        "    \"\"\"\n",
        "    POOL_SIZE = (2, 2)\n",
        "    KERNEL_SIZE = (3, 3)\n",
        "    INPUT_SHAPE = input_shape  # not correct\n",
        "\n",
        "    # declare tensors for two input images to be compared\n",
        "    left_input = Input(INPUT_SHAPE)\n",
        "    right_input = Input(INPUT_SHAPE)\n",
        "\n",
        "    print(left_input.shape)\n",
        "\n",
        "    # for filters early layers should have less (more abstract) while later layers gain more filters\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(6, KERNEL_SIZE, activation='relu',\n",
        "                     input_shape=INPUT_SHAPE, kernel_regularizer=l2(0.002)))\n",
        "    model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
        "\n",
        "    model.add(Conv2D(12, KERNEL_SIZE, activation='relu',\n",
        "                     kernel_regularizer=l2(0.002)))\n",
        "    model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.45))\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.005)))\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.005)))\n",
        "\n",
        "\n",
        "    left_image_encoded = model(left_input)\n",
        "    right_image_encoded = model(right_input)\n",
        "\n",
        "    contrastive_layer = Lambda(lambda tensors: euclidean_distance(tensors[0],tensors[1]))\n",
        "\n",
        "    distance = contrastive_layer([left_image_encoded, right_image_encoded])\n",
        "\n",
        "    prediction = Dense(1, activation='sigmoid')(distance)\n",
        "\n",
        "    return Model(inputs=[left_input, right_input], outputs=prediction)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a4EHIUudWnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def fit_model(lr=None, batch_size=None, val_split=None, epochs=None):\n",
        "    if lr is None:\n",
        "        optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "    else:\n",
        "        optimizer = tf.keras.optimizers.Adam(lr)\n",
        "    if batch_size is None:\n",
        "        batch_size = 32\n",
        "\n",
        "    if val_split is None:\n",
        "        val_split = 0.15\n",
        "\n",
        "    if epochs is None:\n",
        "        epochs = 100\n",
        "\n",
        "    train_test_data = fetch_train_test()\n",
        "    x_train, y_train = train_test_data['x_train'], train_test_data['y_train']\n",
        "    input_shape = x_train[0][0].shape\n",
        "    model = siamese_model(input_shape)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit([x_train[:, 0], x_train[:, 1]], y_train,\n",
        "              epochs=epochs, batch_size=batch_size, validation_split=val_split)\n",
        "\n",
        "    x_test, y_test = train_test_data['x_test'], train_test_data['y_test']\n",
        "\n",
        "    print(model.evaluate([x_test[:, 0], x_test[:, 1]], y_test))\n",
        "    print(model.metrics_names)\n",
        "    model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpbCW2gZddPT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "529582f7-cd15-4e54-a9d5-d32a91c1d3e7"
      },
      "source": [
        "fit_model(epochs=300,lr=0.001)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 64, 64, 1)\n",
            "Train on 6683 samples, validate on 1180 samples\n",
            "Epoch 1/300\n",
            "6683/6683 [==============================] - 5s 776us/sample - loss: 1.0441 - acc: 0.5179 - val_loss: 0.7490 - val_acc: 0.5059\n",
            "Epoch 2/300\n",
            "6683/6683 [==============================] - 3s 457us/sample - loss: 0.7145 - acc: 0.5460 - val_loss: 0.7098 - val_acc: 0.5339\n",
            "Epoch 3/300\n",
            "6683/6683 [==============================] - 3s 447us/sample - loss: 0.6943 - acc: 0.5698 - val_loss: 0.7073 - val_acc: 0.5754\n",
            "Epoch 4/300\n",
            "6683/6683 [==============================] - 3s 472us/sample - loss: 0.6884 - acc: 0.5857 - val_loss: 0.6868 - val_acc: 0.6008\n",
            "Epoch 5/300\n",
            "6683/6683 [==============================] - 3s 489us/sample - loss: 0.6829 - acc: 0.5975 - val_loss: 0.6988 - val_acc: 0.5720\n",
            "Epoch 6/300\n",
            "6683/6683 [==============================] - 3s 498us/sample - loss: 0.6788 - acc: 0.6030 - val_loss: 0.6904 - val_acc: 0.5729\n",
            "Epoch 7/300\n",
            "6683/6683 [==============================] - 3s 480us/sample - loss: 0.6785 - acc: 0.6105 - val_loss: 0.6859 - val_acc: 0.6025\n",
            "Epoch 8/300\n",
            "6683/6683 [==============================] - 3s 491us/sample - loss: 0.6759 - acc: 0.6204 - val_loss: 0.6780 - val_acc: 0.6229\n",
            "Epoch 9/300\n",
            "6683/6683 [==============================] - 3s 474us/sample - loss: 0.6721 - acc: 0.6271 - val_loss: 0.6713 - val_acc: 0.6322\n",
            "Epoch 10/300\n",
            "6683/6683 [==============================] - 3s 482us/sample - loss: 0.6715 - acc: 0.6240 - val_loss: 0.6752 - val_acc: 0.6381\n",
            "Epoch 11/300\n",
            "6683/6683 [==============================] - 3s 445us/sample - loss: 0.6717 - acc: 0.6276 - val_loss: 0.6753 - val_acc: 0.6186\n",
            "Epoch 12/300\n",
            "6683/6683 [==============================] - 3s 446us/sample - loss: 0.6678 - acc: 0.6346 - val_loss: 0.6716 - val_acc: 0.6458\n",
            "Epoch 13/300\n",
            "6683/6683 [==============================] - 3s 484us/sample - loss: 0.6661 - acc: 0.6406 - val_loss: 0.6702 - val_acc: 0.6390\n",
            "Epoch 14/300\n",
            "6683/6683 [==============================] - 3s 473us/sample - loss: 0.6639 - acc: 0.6343 - val_loss: 0.6670 - val_acc: 0.6483\n",
            "Epoch 15/300\n",
            "6683/6683 [==============================] - 3s 450us/sample - loss: 0.6589 - acc: 0.6448 - val_loss: 0.6635 - val_acc: 0.6517\n",
            "Epoch 16/300\n",
            "6683/6683 [==============================] - 3s 448us/sample - loss: 0.6576 - acc: 0.6419 - val_loss: 0.6651 - val_acc: 0.6534\n",
            "Epoch 17/300\n",
            "6683/6683 [==============================] - 3s 434us/sample - loss: 0.6573 - acc: 0.6467 - val_loss: 0.6615 - val_acc: 0.6551\n",
            "Epoch 18/300\n",
            "6683/6683 [==============================] - 3s 435us/sample - loss: 0.6547 - acc: 0.6558 - val_loss: 0.6651 - val_acc: 0.6449\n",
            "Epoch 19/300\n",
            "6683/6683 [==============================] - 3s 442us/sample - loss: 0.6505 - acc: 0.6587 - val_loss: 0.6652 - val_acc: 0.6619\n",
            "Epoch 20/300\n",
            "6683/6683 [==============================] - 3s 435us/sample - loss: 0.6496 - acc: 0.6657 - val_loss: 0.6694 - val_acc: 0.6602\n",
            "Epoch 21/300\n",
            "6683/6683 [==============================] - 3s 444us/sample - loss: 0.6489 - acc: 0.6735 - val_loss: 0.6561 - val_acc: 0.6737\n",
            "Epoch 22/300\n",
            "6683/6683 [==============================] - 3s 450us/sample - loss: 0.6418 - acc: 0.6807 - val_loss: 0.6551 - val_acc: 0.6720\n",
            "Epoch 23/300\n",
            "6683/6683 [==============================] - 3s 461us/sample - loss: 0.6398 - acc: 0.6868 - val_loss: 0.6571 - val_acc: 0.6754\n",
            "Epoch 24/300\n",
            "6683/6683 [==============================] - 3s 455us/sample - loss: 0.6362 - acc: 0.6897 - val_loss: 0.6472 - val_acc: 0.6737\n",
            "Epoch 25/300\n",
            "6683/6683 [==============================] - 3s 460us/sample - loss: 0.6335 - acc: 0.6898 - val_loss: 0.6502 - val_acc: 0.6788\n",
            "Epoch 26/300\n",
            "6683/6683 [==============================] - 3s 440us/sample - loss: 0.6291 - acc: 0.6955 - val_loss: 0.6449 - val_acc: 0.6847\n",
            "Epoch 27/300\n",
            "6683/6683 [==============================] - 3s 447us/sample - loss: 0.6305 - acc: 0.6924 - val_loss: 0.6470 - val_acc: 0.6864\n",
            "Epoch 28/300\n",
            "6683/6683 [==============================] - 3s 449us/sample - loss: 0.6275 - acc: 0.6936 - val_loss: 0.6395 - val_acc: 0.6949\n",
            "Epoch 29/300\n",
            "6683/6683 [==============================] - 3s 442us/sample - loss: 0.6236 - acc: 0.6998 - val_loss: 0.6365 - val_acc: 0.6932\n",
            "Epoch 30/300\n",
            "6683/6683 [==============================] - 3s 445us/sample - loss: 0.6245 - acc: 0.7025 - val_loss: 0.6419 - val_acc: 0.6983\n",
            "Epoch 31/300\n",
            "6683/6683 [==============================] - 3s 436us/sample - loss: 0.6213 - acc: 0.6997 - val_loss: 0.6301 - val_acc: 0.7025\n",
            "Epoch 32/300\n",
            "6683/6683 [==============================] - 3s 441us/sample - loss: 0.6179 - acc: 0.7019 - val_loss: 0.6313 - val_acc: 0.6949\n",
            "Epoch 33/300\n",
            "6683/6683 [==============================] - 3s 440us/sample - loss: 0.6099 - acc: 0.7157 - val_loss: 0.6238 - val_acc: 0.7051\n",
            "Epoch 34/300\n",
            "6683/6683 [==============================] - 3s 447us/sample - loss: 0.6149 - acc: 0.7055 - val_loss: 0.6268 - val_acc: 0.7034\n",
            "Epoch 35/300\n",
            "6683/6683 [==============================] - 3s 438us/sample - loss: 0.6099 - acc: 0.7181 - val_loss: 0.6301 - val_acc: 0.7119\n",
            "Epoch 36/300\n",
            "6683/6683 [==============================] - 3s 446us/sample - loss: 0.6110 - acc: 0.7105 - val_loss: 0.6192 - val_acc: 0.7169\n",
            "Epoch 37/300\n",
            "6683/6683 [==============================] - 3s 448us/sample - loss: 0.6054 - acc: 0.7161 - val_loss: 0.6191 - val_acc: 0.7169\n",
            "Epoch 38/300\n",
            "6683/6683 [==============================] - 3s 444us/sample - loss: 0.6093 - acc: 0.7163 - val_loss: 0.6258 - val_acc: 0.7212\n",
            "Epoch 39/300\n",
            "6683/6683 [==============================] - 3s 448us/sample - loss: 0.6100 - acc: 0.7185 - val_loss: 0.6171 - val_acc: 0.7203\n",
            "Epoch 40/300\n",
            "6683/6683 [==============================] - 3s 445us/sample - loss: 0.6027 - acc: 0.7313 - val_loss: 0.6153 - val_acc: 0.7246\n",
            "Epoch 41/300\n",
            "6683/6683 [==============================] - 3s 447us/sample - loss: 0.5990 - acc: 0.7307 - val_loss: 0.6132 - val_acc: 0.7186\n",
            "Epoch 42/300\n",
            "6683/6683 [==============================] - 3s 447us/sample - loss: 0.5974 - acc: 0.7302 - val_loss: 0.6119 - val_acc: 0.7220\n",
            "Epoch 43/300\n",
            "6683/6683 [==============================] - 3s 444us/sample - loss: 0.5908 - acc: 0.7322 - val_loss: 0.6117 - val_acc: 0.7169\n",
            "Epoch 44/300\n",
            "6683/6683 [==============================] - 3s 447us/sample - loss: 0.5975 - acc: 0.7311 - val_loss: 0.6088 - val_acc: 0.7364\n",
            "Epoch 45/300\n",
            "6683/6683 [==============================] - 3s 430us/sample - loss: 0.5902 - acc: 0.7359 - val_loss: 0.6025 - val_acc: 0.7347\n",
            "Epoch 46/300\n",
            "6683/6683 [==============================] - 3s 448us/sample - loss: 0.5932 - acc: 0.7325 - val_loss: 0.6089 - val_acc: 0.7229\n",
            "Epoch 47/300\n",
            "6683/6683 [==============================] - 3s 444us/sample - loss: 0.5899 - acc: 0.7405 - val_loss: 0.5980 - val_acc: 0.7483\n",
            "Epoch 48/300\n",
            "6683/6683 [==============================] - 3s 450us/sample - loss: 0.5896 - acc: 0.7337 - val_loss: 0.6060 - val_acc: 0.7424\n",
            "Epoch 49/300\n",
            "6683/6683 [==============================] - 3s 448us/sample - loss: 0.5854 - acc: 0.7483 - val_loss: 0.5933 - val_acc: 0.7475\n",
            "Epoch 50/300\n",
            "6683/6683 [==============================] - 3s 439us/sample - loss: 0.5871 - acc: 0.7372 - val_loss: 0.5937 - val_acc: 0.7492\n",
            "Epoch 51/300\n",
            "6683/6683 [==============================] - 3s 454us/sample - loss: 0.5811 - acc: 0.7470 - val_loss: 0.5920 - val_acc: 0.7500\n",
            "Epoch 52/300\n",
            "6683/6683 [==============================] - 3s 457us/sample - loss: 0.5830 - acc: 0.7462 - val_loss: 0.5928 - val_acc: 0.7500\n",
            "Epoch 53/300\n",
            "6683/6683 [==============================] - 3s 493us/sample - loss: 0.5730 - acc: 0.7568 - val_loss: 0.5986 - val_acc: 0.7314\n",
            "Epoch 54/300\n",
            "6683/6683 [==============================] - 4s 534us/sample - loss: 0.5751 - acc: 0.7577 - val_loss: 0.5952 - val_acc: 0.7466\n",
            "Epoch 55/300\n",
            "6683/6683 [==============================] - 4s 531us/sample - loss: 0.5731 - acc: 0.7507 - val_loss: 0.5903 - val_acc: 0.7449\n",
            "Epoch 56/300\n",
            "6683/6683 [==============================] - 3s 477us/sample - loss: 0.5707 - acc: 0.7559 - val_loss: 0.5824 - val_acc: 0.7441\n",
            "Epoch 57/300\n",
            "6683/6683 [==============================] - 3s 469us/sample - loss: 0.5763 - acc: 0.7530 - val_loss: 0.5995 - val_acc: 0.7339\n",
            "Epoch 58/300\n",
            "6683/6683 [==============================] - 3s 488us/sample - loss: 0.5654 - acc: 0.7615 - val_loss: 0.5898 - val_acc: 0.7542\n",
            "Epoch 59/300\n",
            "6683/6683 [==============================] - 3s 481us/sample - loss: 0.5665 - acc: 0.7673 - val_loss: 0.5801 - val_acc: 0.7508\n",
            "Epoch 60/300\n",
            "6683/6683 [==============================] - 3s 483us/sample - loss: 0.5665 - acc: 0.7624 - val_loss: 0.5849 - val_acc: 0.7492\n",
            "Epoch 61/300\n",
            "6683/6683 [==============================] - 3s 481us/sample - loss: 0.5645 - acc: 0.7555 - val_loss: 0.5797 - val_acc: 0.7492\n",
            "Epoch 62/300\n",
            "6683/6683 [==============================] - 3s 472us/sample - loss: 0.5599 - acc: 0.7687 - val_loss: 0.5765 - val_acc: 0.7695\n",
            "Epoch 63/300\n",
            "6683/6683 [==============================] - 3s 469us/sample - loss: 0.5570 - acc: 0.7691 - val_loss: 0.5728 - val_acc: 0.7754\n",
            "Epoch 64/300\n",
            "6683/6683 [==============================] - 3s 463us/sample - loss: 0.5595 - acc: 0.7741 - val_loss: 0.5925 - val_acc: 0.7568\n",
            "Epoch 65/300\n",
            "6683/6683 [==============================] - 3s 453us/sample - loss: 0.5631 - acc: 0.7628 - val_loss: 0.5814 - val_acc: 0.7525\n",
            "Epoch 66/300\n",
            "6683/6683 [==============================] - 3s 457us/sample - loss: 0.5575 - acc: 0.7708 - val_loss: 0.5812 - val_acc: 0.7610\n",
            "Epoch 67/300\n",
            "6683/6683 [==============================] - 3s 470us/sample - loss: 0.5607 - acc: 0.7642 - val_loss: 0.5601 - val_acc: 0.7695\n",
            "Epoch 68/300\n",
            "6683/6683 [==============================] - 3s 458us/sample - loss: 0.5485 - acc: 0.7778 - val_loss: 0.5909 - val_acc: 0.7475\n",
            "Epoch 69/300\n",
            "6683/6683 [==============================] - 3s 447us/sample - loss: 0.5551 - acc: 0.7715 - val_loss: 0.5794 - val_acc: 0.7602\n",
            "Epoch 70/300\n",
            "6683/6683 [==============================] - 3s 442us/sample - loss: 0.5513 - acc: 0.7703 - val_loss: 0.5729 - val_acc: 0.7525\n",
            "Epoch 71/300\n",
            "6683/6683 [==============================] - 3s 436us/sample - loss: 0.5506 - acc: 0.7750 - val_loss: 0.5702 - val_acc: 0.7610\n",
            "Epoch 72/300\n",
            "6683/6683 [==============================] - 3s 458us/sample - loss: 0.5495 - acc: 0.7770 - val_loss: 0.5712 - val_acc: 0.7619\n",
            "Epoch 73/300\n",
            "6683/6683 [==============================] - 3s 466us/sample - loss: 0.5460 - acc: 0.7791 - val_loss: 0.5676 - val_acc: 0.7729\n",
            "Epoch 74/300\n",
            "6683/6683 [==============================] - 3s 443us/sample - loss: 0.5435 - acc: 0.7805 - val_loss: 0.5627 - val_acc: 0.7737\n",
            "Epoch 75/300\n",
            "6683/6683 [==============================] - 3s 454us/sample - loss: 0.5543 - acc: 0.7748 - val_loss: 0.5802 - val_acc: 0.7568\n",
            "Epoch 76/300\n",
            "6683/6683 [==============================] - 3s 451us/sample - loss: 0.5494 - acc: 0.7753 - val_loss: 0.5766 - val_acc: 0.7636\n",
            "Epoch 77/300\n",
            "5728/6683 [========================>.....] - ETA: 0s - loss: 0.5441 - acc: 0.7799"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-e00e80281eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-87-061d71ec8bf3>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(lr, batch_size, val_split, epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     model.fit([x_train[:, 0], x_train[:, 1]], y_train,\n\u001b[0;32m---> 26\u001b[0;31m               epochs=epochs, batch_size=batch_size, validation_split=val_split)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}